{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2eb5b10-bb1b-49f4-a521-ddba6e020736",
   "metadata": {},
   "source": [
    "# 自定义层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca37aef-8b37-46b6-b399-cf751763c261",
   "metadata": {},
   "source": [
    "深度学习成功背后的一个因素是神经网络的灵活性： 我们可以用创造性的方式组合不同的层，从而设计出适用于各种任务的架构。\n",
    "\n",
    "这一节展示如何构建自定义层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612fbc62-73ec-41ba-b95f-09e01702dc7b",
   "metadata": {},
   "source": [
    "## 不带参数的层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefa8c08-cbcf-4ee0-adba-011f373fdc94",
   "metadata": {},
   "source": [
    "首先，我们构造一个没有任何参数的自定义层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d43a76-4679-4a25-9725-2ef538a89bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a799236-b695-43ed-83cc-a9cd116fdcb6",
   "metadata": {},
   "source": [
    "我们看看是否能否正常运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07491e73-9286-4a60-8700-87ba5cadcc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CenteredLayer()\n",
    "layer(torch.FloatTensor([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157f9788-c715-4d86-a0d5-bb115e30080b",
   "metadata": {},
   "source": [
    "现在，我们可以将层作为组件合并到更复杂的模型中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33816d49-7467-455c-a0d4-d3b7da978a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d98e7f-77ec-49d1-b0b3-1f68ce9d7172",
   "metadata": {},
   "source": [
    "作为额外的健全性检查，我们可以在向该网络发送随机数据后，检查均值是否为0。 由于我们处理的是浮点数，因为存储精度的原因，我们仍然可能会看到一个非常小的非零数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31a2e8c2-c8e1-48de-8857-11acc09847c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.5193e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15584af3-7148-4acd-8429-582bb894bd29",
   "metadata": {},
   "source": [
    "## 带参数的层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c475ab-b8ce-435b-96c3-229b75d9d7cd",
   "metadata": {},
   "source": [
    "以上我们知道了如何定义简单的层，下面我们继续定义具有参数的层， 这些参数可以通过训练进行调整。 我们可以使用内置函数来创建参数，这些函数提供一些基本的管理功能。 比如管理访问、初始化、共享、保存和加载模型参数。 这样做的好处之一是：我们不需要为每个自定义层编写自定义的序列化程序。\n",
    "\n",
    "现在，让我们实现自定义版本的全连接层。 回想一下，该层需要两个参数，一个用于表示权重，另一个用于表示偏置项。 在此实现中，我们使用修正线性单元作为激活函数。 该层需要输入参数：in_units和units，分别表示输入数和输出数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b7e93a6-b3e2-4946-99d3-262e3c24b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da1a75-88c4-434d-a811-5c89c3e54cb9",
   "metadata": {},
   "source": [
    "接下来，我们实例化MyLinear类并访问其模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "911378e2-823f-44c8-8ef6-ebd546625148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.0473,  0.2619,  0.7733],\n",
       "        [ 0.7414, -0.2337, -2.6910],\n",
       "        [ 0.5224, -0.5787,  1.2816],\n",
       "        [-0.1637,  0.8391,  1.6121],\n",
       "        [ 0.1398,  0.1692, -0.5022]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = MyLinear(5, 3)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c595e-64d5-40a9-b800-2052304e924f",
   "metadata": {},
   "source": [
    "我们可以使用自定义层直接执行前向传播计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9c60727-2bcf-4cb8-b657-2e9ac5a18533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3233, 0.0000],\n",
       "        [0.0000, 0.0000, 0.6072]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbeba95-35f8-477c-888a-8fef87c08645",
   "metadata": {},
   "source": [
    "我们还可以使用自定义层构建模型，就像使用内置的全连接层一样使用自定义层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfd230be-80fd-41df-8f5b-e713df92076a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.4355],\n",
       "        [0.0000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2f7464-6f2e-498a-bcf0-16901d511e3a",
   "metadata": {},
   "source": [
    "## 小结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf4fbfa-571f-4f70-95f5-e36c47dae5a0",
   "metadata": {},
   "source": [
    "- 我们可以通过基本层类设计自定义层。这允许我们定义灵活的新层，其行为与深度学习框架中的任何现有层不同。\n",
    "- 在自定义层定义完成后，我们就可以在任意环境和网络架构中调用该自定义层。\n",
    "- 层可以有局部参数，这些参数可以通过内置函数创建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d43a30-ee85-4571-86f3-46e4a0ee9630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
